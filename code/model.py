import torch
import torch.nn as nn
from image_encoder import ImageEncoder
from text_encoder import TextEncoder

class MultiModalNet(nn.Module):
    def __init__(self, num_specific=30, num_region=5, d_model=768, num_heads=8, dropout=0.1):
        super().__init__()

        self.image_encoder = ImageEncoder()
        self.text_encoder = TextEncoder()
        
        self.cross_attention = nn.MultiheadAttention(
            embed_dim = d_model, 
            num_heads = num_heads, 
            dropout = dropout, 
            batch_first = True
        )
        
        self.ln = nn.LayerNorm(d_model)
        
        self.dropout = nn.Dropout(dropout)

        self.classifier_specific = nn.Linear(d_model, num_specific)
        
        self.classifier_region = nn.Linear(d_model, num_region)
        
    def forward(self, images, text_list):
        img_feats = self.image_encoder(images)
        
        txt_feats, txt_mask = self.text_encoder(text_list)
        
        padding_mask = (txt_mask == 0).bool()
        
        attn_output, _ = self.cross_attention(
            query = img_feats,
            key = txt_feats,
            value = txt_feats,
            key_padding_mask = padding_mask
        )
        
        fused_feats = self.ln(img_feats + attn_output)
        
        cls_feat = fused_feats[:, 0, :]
        cls_feat = self.dropout(cls_feat)
        
        logits_specific = self.classifier_specific(cls_feat)
        
        logits_region = self.classifier_region(cls_feat)
        
        return logits_specific, logits_region
    
class MultiModalNet_NoRegion(nn.Module):
    def __init__(self, num_specific=30, d_model=768, num_heads=8, dropout=0.1):
        super().__init__()
        self.image_encoder = ImageEncoder()
        self.text_encoder = TextEncoder()
        
        self.cross_attention = nn.MultiheadAttention(
            embed_dim = d_model, 
            num_heads = num_heads, 
            dropout = dropout, 
            batch_first = True
        )
        
        self.ln = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)

        self.classifier_specific = nn.Linear(d_model, num_specific)

    def forward(self, images, text_list):
        img_feats = self.image_encoder(images)
        txt_feats, txt_mask = self.text_encoder(text_list)
        padding_mask = (txt_mask == 0).bool()
        
        attn_output, _ = self.cross_attention(
            query = img_feats,
            key = txt_feats,
            value = txt_feats,
            key_padding_mask = padding_mask
        )
        
        fused_feats = self.ln(img_feats + attn_output)
        cls_feat = fused_feats[:, 0, :]
        cls_feat = self.dropout(cls_feat)
        
        logits_specific = self.classifier_specific(cls_feat)
        
        return logits_specific    

if __name__ == "__main__":
    # å‡†å¤‡å‡æ•°æ® (Batch Size = 2)
    dummy_img = torch.randn(2, 3, 224, 224)
    dummy_txt = ["Lung opacity found.", "No findings."]
    
    print("="*40)
    print("ğŸ§ª æµ‹è¯• 1: åŸå®Œæ•´æ¨¡å‹ (MultiModalNet)")
    print("="*40)
    try:
        model = MultiModalNet()
        out_spec, out_reg = model(dummy_img, dummy_txt)
        
        print(f"è¾“å…¥å›¾ç‰‡: {dummy_img.shape}")
        print(f"Specific Output: {out_spec.shape}")
        print(f"Region Output:   {out_reg.shape}")
        
        if out_spec.shape == (2, 30) and out_reg.shape == (2, 5):
            print("âœ… åŸæ¨¡å‹æµ‹è¯•é€šè¿‡ï¼è¾“å‡ºä¸¤ä¸ªç»“æœã€‚")
        else:
            print("âŒ åŸæ¨¡å‹è¾“å‡ºå½¢çŠ¶ä¸å¯¹ï¼")
            
    except Exception as e:
        print(f"âŒ åŸæ¨¡å‹è¿è¡ŒæŠ¥é”™: {e}")

    print("\n" + "="*40)
    print("ğŸ§ª æµ‹è¯• 2: æ¶ˆèæ¨¡å‹ (MultiModalNet_NoRegion)")
    print("="*40)
    try:
        # å®ä¾‹åŒ–æ¶ˆèæ¨¡å‹
        model_ablation = MultiModalNet_NoRegion()
        
        # âš ï¸ æ³¨æ„ï¼šè¿™é‡Œåªèƒ½æ¥æ”¶ä¸€ä¸ªè¿”å›å€¼
        output = model_ablation(dummy_img, dummy_txt)
        
        print(f"è¾“å…¥å›¾ç‰‡: {dummy_img.shape}")
        print(f"è¾“å‡ºç»“æœ: {output.shape} (åº”è¯¥åªæœ‰ Specific)")
        
        # éªŒè¯é€»è¾‘ï¼šå¿…é¡»æ˜¯ (2, 30) ä¸”ä¸èƒ½æ˜¯ tuple
        if isinstance(output, tuple):
            print("âŒ é”™è¯¯ï¼šæ¨¡å‹ä¾ç„¶è¿”å›äº† Tupleï¼Œè¯´æ˜æ²¡æ”¹å¹²å‡€ï¼")
        elif output.shape == (2, 30):
            print("âœ… æ¶ˆèæ¨¡å‹æµ‹è¯•é€šè¿‡ï¼åªè¾“å‡ºäº† Specific åˆ†ç±»ç»“æœã€‚")
        else:
            print(f"âŒ å½¢çŠ¶é”™è¯¯ï¼šæœŸæœ› (2, 30)ï¼Œå®é™… {output.shape}")

    except Exception as e:
        print(f"âŒ æ¶ˆèæ¨¡å‹è¿è¡ŒæŠ¥é”™: {e}")